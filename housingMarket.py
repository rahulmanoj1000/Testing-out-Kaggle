# -*- coding: utf-8 -*-
"""kaggle.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UwKdB66Dse3gL12xJrK0W7ryxbx8Sjqu
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.pipeline import Pipeline
import sklearn
from sklearn import neighbors
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OrdinalEncoder
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error

df = pd.read_csv("/content/drive/MyDrive/Data For ML/train.csv")
df_test = pd.read_csv("/content/drive/MyDrive/Data For ML/test.csv")
# checker = pd.read_csv("/content/drive/MyDrive/Data For ML/sample_submission.csv")

df.head()

df.info()
# df_test.info()

#This is done to remove columns where too many values are missing(but on hindsight it reducing accuracy so i removed this step)
for column in df.columns:
    if (df[column].isnull().sum())>700:
        df = df.drop([column],axis = 1)
        df_test = df_test.drop([column],axis = 1)

# df.drop(['Alley'],axis = 1)
# df.drop(['FireplaceQu'],axis = 1)
# df.drop(['PoolQC'],axis = 1)
# df.drop(['Fence'],axis = 1)
# df.drop(['MiscFeature'],axis = 1)

df.info()
# df_test.info()

##If this is not done sklearn will throw error because some objects are present in training but not testing
##Collecting all the objects(strings)
object_cols = [col for col in df.columns if df[col].dtype == 'object']
##Checking if they are present in both df and df_test
good_label_cols = [col for col in object_cols if set(df_test[col]).issubset(set(df[col]))]

bad_label_cols = list(set(object_cols)-set(good_label_cols))
print('Categorical columns that will be ordinal encoded:', good_label_cols)
print('\nCategorical columns that will be dropped from the dataset:', bad_label_cols)

print(object_cols)

##Ordinal Encoder changes all string(objects) in the columns to integers
ordinal_encoder = OrdinalEncoder()
df = df.drop(bad_label_cols, axis = 1)
df_test = df_test.drop(bad_label_cols, axis = 1)
df[good_label_cols] = ordinal_encoder.fit_transform(df[good_label_cols])
df_test[good_label_cols] =  ordinal_encoder.transform(df_test[good_label_cols])

df = pd.DataFrame(df)
print(df)

Y = df['SalePrice']
df = df.drop(['SalePrice'],axis = 1)
df_2 = df

Y

##Simple Imputer removes all the NaN values are replaces it appropriately 
from sklearn.impute import SimpleImputer


my_imputer = SimpleImputer()
df = pd.DataFrame(my_imputer.fit_transform(df))
df_test = pd.DataFrame(my_imputer.transform(df_test))

## This is to bring back the column names that gets droped when datamanupulation is done by using sklearn(eg:all headers are missing after using simple imputer)
# special_2 = pd.DataFrame(special_2, columns = special.columns)(this is from another project)

df.head()

df_2.head()

# df = pd.DataFrame(df, columns = df_2.columns)

# print(df)

X = df

X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.2)

clf = LinearRegression()
clf.fit(X_test,Y_test)
accuracy = clf.score(X_test, Y_test)
print(accuracy)
pred = clf.predict(df_test)

from xgboost import XGBRegressor
classifier = XGBRegressor(n_estimators=1000, learning_rate=0.05, n_jobs=4)
classifier.fit(X_train, Y_train, 
             early_stopping_rounds=5, 
             eval_set=[(X_test, Y_test)], 
             verbose=False)

X_test = df_test

X_test

from sklearn.metrics import mean_squared_error
pred = classifier.predict(X_test)
# classifier.score(X_test, Y_test)

print(pred)
# pred

# checker.drop(['Id'], axis = 1, inplace = True)

# checker.to_numpy()
# print(checker)
# print(mean_absolute_error(checker,pred))

[sub_df["Id"],pred]

pred = pd.DataFrame(pred)
sub_df = pd.read_csv("/content/drive/MyDrive/Data For ML/Copy of sample_submission.csv")
datasets = pd.concat([sub_df["Id"],pred],axis=1)
datasets.columns = ['Id','SalePrice']
datasets.to_csv("/content/drive/MyDrive/Data For ML/Copy of sample_submission.csv",index = False)

ls -l